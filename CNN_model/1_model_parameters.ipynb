{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-Mp_USHxCDAF"},"source":["## 了解 CNN 模型的結構及參數個數\n","參考 MNIST 圖像 28x28 為輸入尺寸，此範例僅說明建模，尚未使用該資料集"]},{"cell_type":"markdown","metadata":{"id":"tY7uqh2nHHSH"},"source":["# 1. 載入模組"]},{"cell_type":"code","metadata":{"id":"oZ92H1bwDLCf"},"source":["# 匯入模組\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","\n","#Conv2D 卷積層, MaxPooling2D 池化層, Flatten 平坦層\n","from keras.layers import Conv2D, MaxPooling2D, Flatten\n","# from keras import backend as K\n","# from keras import models\n","\n","# 繪圖模組織\n","from keras.utils import plot_model  # 繪製模型圖"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QkTKfHQH1xho"},"source":["# 2. CNN 模型建模 - 一維單色圖"]},{"cell_type":"markdown","metadata":{"id":"lRV2mKpv66bQ"},"source":["### 2-0. 共同參數"]},{"cell_type":"code","metadata":{"id":"lZzmkDQ4SeWr"},"source":["# 定義參數\n","(img_rows, img_cols) = (28, 28)\n","num_classes = 10  # 分類數量\n","\n","input_shape = (img_rows, img_cols, 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XNL1D9cO2Zox"},"source":["## 2-1. 模型(1)"]},{"cell_type":"code","metadata":{"id":"ow2WWLpJ2JRO"},"source":["# 建模(1)\n","model = Sequential(name='CNN-mnist(1)')\n","# 卷積1層 kernel_size=(3, 3) 使用 3*3 像素為單位運算擷取特徵\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n","# 平坦層:將特徵值轉為一維矩陣，供後續的全連接層使用\n","model.add(Flatten())\n","# 全連接層，原理同 MLP\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","# 繪製模型圖\n","plot_model(model, show_shapes=True, show_layer_names=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wKdQFUrLdjdh"},"source":["## 2-2. 模型(2)"]},{"cell_type":"code","metadata":{"id":"VP3Ijlg7x5Qk"},"source":["# 建模(2)\n","model = Sequential(name='CNN-mnist(2)')\n","# 卷積1層 kernel_size=(3, 3) 使用 3*3 像素為單位運算擷取特徵\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, name='Conv-1'))\n","# 卷積2層 使用 3*3 像素為單位運算擷取特徵\n","model.add(Conv2D(64, (3, 3), activation='relu', name='Conv-2'))\n","# 平坦層:將特徵值轉為一維矩陣，供後續的全連接層使用\n","model.add(Flatten())\n","# 全連接層，原理同 MLP\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","# 繪製模型圖\n","plot_model(model, show_shapes=True, show_layer_names=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XUA7LPNudliw"},"source":["## 2-3. 模型(3)"]},{"cell_type":"code","metadata":{"id":"YTT6S23dI9_l"},"source":["# 建模(3)\n","model = Sequential(name='CNN-mnist(3)')\n","# 卷積1層 kernel_size=(5, 5) 使用 5*5 像素為單位運算擷取特徵\n","model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape, name='Conv-1'))\n","# 卷積2層 使用 3*3 像素為單位運算擷取特徵，步長設為2\n","model.add(Conv2D(64, (3, 3), strides=(2, 2), activation='relu', name='Conv-2'))\n","# 平坦層:將特徵值轉為一維矩陣，供後續的全連接層使用\n","model.add(Flatten())\n","# 全連接層，原理同 MLP\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","# 繪製模型圖\n","plot_model(model, show_shapes=True, show_layer_names=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UqFlYmkBdnl0"},"source":["## 2-4. 模型(4)"]},{"cell_type":"code","metadata":{"id":"1fs6fJbBLDAm"},"source":["# 建模(4) --- 由(2)延伸\n","model = Sequential(name='CNN-mnist(4)')\n","# 卷積層1 kernel_size=(3, 3) 使用 3*3 像素為單位運算擷取特徵\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, name='Conv-1'))\n","# 池化層1 使用 2*2 子區域運算最大值\n","model.add(MaxPooling2D(pool_size=(2, 2), name='Pooling-1'))\n","# 卷積層2 使用 3*3 像素為單位運算擷取特徵\n","model.add(Conv2D(64, (3, 3), activation='relu', name='Conv-2'))\n","# 池化層2 使用 2*2 子區域運算最大值\n","model.add(MaxPooling2D(pool_size=(2, 2), name='Pooling-2'))\n","# 平坦層:將特徵值轉為一維矩陣，供後續的全連接層使用\n","model.add(Flatten())\n","# 拋棄層 隨機丟棄參數，避免過擬合\n","model.add(Dropout(0.25))\n","# 全連接層，原理同 MLP\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","# 繪製模型圖\n","plot_model(model, show_shapes=True, show_layer_names=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x7r93OjJ7J8D"},"source":["# 3. CNN 模型建模 - 三維彩色圖"]},{"cell_type":"code","metadata":{"id":"2hZud4JJ7Rfn"},"source":["# 定義參數\n","(img_rows, img_cols) = (28, 28)\n","num_classes = 10  # 分類數量\n","\n","input_shape = (img_rows, img_cols, 3)  # 彩色 RGB 三 Channels\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXDr5xFX7lMi"},"source":["# 建模 --- 由 (2) 延伸\n","model = Sequential(name='CNN (RGB)')\n","# 卷積1層 kernel_size=(3, 3) 使用 3*3 像素及 3 channels 為單位運算擷取特徵\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, name='Conv-1'))\n","# 卷積2層 使用 3*3 像素為單位運算擷取特徵\n","model.add(Conv2D(64, (3, 3), activation='relu', name='Conv-2'))\n","# 平坦層:將特徵值轉為一維矩陣，供後續的全連接層使用\n","model.add(Flatten())\n","# 全連接層，原理同 MLP\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","# 繪製模型圖\n","plot_model(model, show_shapes=True, show_layer_names=False)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eRAeuawSlpJ0"},"source":["# 4. 建模練習"]},{"cell_type":"markdown","metadata":{"id":"H_JcODcIRpDV"},"source":["### 4-1. 練習(1)：依據圖上的定義建立模型\n","![](https://miro.medium.com/max/3744/1*SGPGG7oeSvVlV5sOSQ2iZw.png)\n","Ref: https://towardsdatascience.com/mnist-handwritten-digits-classification-using-a-convolutional-neural-network-cnn-af5fafbc35e9"]},{"cell_type":"code","metadata":{"id":"yQl7h-JiR1qb"},"source":["# 建模\n","\n","demo_input_shape = (28, 28, 1)\n","demo_num_classes = 10\n","\n","model = Sequential(name='CNN model')\n","model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=demo_input_shape, name='Conv-1'))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=2, name='MaxPool-1'))\n","model.add(Conv2D(64, (3, 3), padding='same', activation='relu', name='Conv-2'))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=2, name='MaxPool-2'))\n","model.add(Flatten(name='Flatten'))\n","model.add(Dense(128, activation='relu', name='FC-1'))\n","model.add(Dense(demo_num_classes, activation='softmax'))\n","\n","model.summary()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xXF9CzwPRc7O"},"source":["### 4-2. 練習(2)：依據參考文章建模並計算參數個數\n","Ref: https://learnopencv.com/number-of-parameters-and-tensor-sizes-in-convolutional-neural-network/"]},{"cell_type":"code","metadata":{"id":"-F28QFE1qFOn"},"source":["# 建模\n","\n","demo_input_shape = (227, 227, 3)\n","demo_num_classes = 1000\n","\n","model = Sequential(name='CNN model')\n","model.add(Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=demo_input_shape, name='Conv-1'))\n","model.add(MaxPooling2D(pool_size=(3, 3), strides=2, name='MaxPool-1'))\n","model.add(Conv2D(256, (5, 5), padding='same', activation='relu', name='Conv-2'))\n","model.add(MaxPooling2D(pool_size=(3, 3), strides=2, name='MaxPool-2'))\n","model.add(Conv2D(384, (3, 3), padding='same', activation='relu', name='Conv-3'))\n","model.add(Conv2D(384, (3, 3), padding='same', activation='relu', name='Conv-4'))\n","model.add(Conv2D(256, (3, 3), padding='same', activation='relu', name='Conv-5'))\n","model.add(MaxPooling2D(pool_size=(3, 3), strides=2, name='MaxPool-3'))\n","model.add(Flatten(name='Flatten'))\n","model.add(Dense(4096, activation='relu', name='FC-1'))\n","model.add(Dense(4096, activation='relu', name='FC-2'))\n","model.add(Dense(demo_num_classes, activation='softmax'))\n","\n","model.summary()\n"],"execution_count":null,"outputs":[]}]}