{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-Mp_USHxCDAF"},"source":["# 影像圖片分類深度學習模型 - MLP (mnist)"]},{"cell_type":"markdown","metadata":{"id":"HqHuXCCNk-Cx"},"source":["## 模型與學習參數調整\n","進行下列調整後並比較結果\n","- model1 原本的模型\n","- model2 將隱藏層神經元個數增加到 784 個\n","- model3 新增一層隱藏層，神經元個數 256, 256 個\n","- model4 增加 Dropout 層 (50%)"]},{"cell_type":"markdown","metadata":{"id":"9Sf_PcSrElFk"},"source":["## <font color='BLUE'>大綱:</font>\n","1. 載入影像資料集及預處理\n","2. 各種 MLP 模型參數\n","3. 訓練與分析\n"]},{"cell_type":"markdown","metadata":{"id":"tY7uqh2nHHSH"},"source":["# 1. 載入影像資料集及預處理"]},{"cell_type":"code","metadata":{"id":"MWB_6L9x2P2B"},"source":["# 匯入模組\n","import tensorflow\n","import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","# plt.style.use('classic') #設定主題配色\n","\n","from tensorflow.python.keras.utils import np_utils  # label 轉為 one-hot-encoding\n","from tensorflow.keras.models import Sequential  # 序列模型工具\n","from tensorflow.keras.layers import Dense  # 全連接層\n","from tensorflow.keras.layers import Dropout  # Drouout 層\n","\n","np.random.seed(10)\n","\n","# 載入手寫數字數據集\n","from keras.datasets import mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# 數據預處理 1.將二維矩陣轉成一維，image像素整數int轉成浮點數float\n","x_train_new = x_train.reshape(60000, 28*28).astype('float32')\n","x_test_new = x_test.reshape(10000, 28*28).astype('float32')\n","\n","# 數據預處理 2.標準化0~1浮點數 Normalization\n","x_train_norm = x_train_new / 255\n","x_test_norm = x_test_new / 255\n","\n","# One-Hot Encoding\n","y_train_onehot = np_utils.to_categorical(y_train)  #將 training 的 label 進行 one-hot encoding\n","y_test_onehot = np_utils.to_categorical(y_test) # 將測試的 labels 進行 one-hot encoding\n","\n","print(x_train_norm.shape)\n","print(y_train_onehot.shape)\n","print(x_test_norm.shape)\n","print(y_test_onehot.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pRpV7ZJjaiw"},"source":["# 2. 各種 MLP 模型參數"]},{"cell_type":"markdown","metadata":{"id":"XEWD79oN-M3b"},"source":["### 建立模型 多層感知模型MLP(Multilayer Perceptron)\n","\n","輸入層 (x) 共有 28x28=784 個神經元\n","\n","輸出層 (y) 共有 10 個 神經元(分10類) One-hot encoding\n"]},{"cell_type":"code","metadata":{"id":"dMLA_zbe9eAc"},"source":["# 建立模型(1)\n","model1 = Sequential(name='MLP-1')\n","model1.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu'))\n","model1.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n","\n","# 建立模型(2)\n","model2 = Sequential(name='MLP-2')\n","model2.add(Dense(units=784, input_dim=784, kernel_initializer='normal', activation='relu'))\n","model2.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n","\n","# 建立模型(3)\n","model3 = Sequential(name='MLP-3')\n","model3.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu'))\n","model3.add(Dense(units=256, kernel_initializer='normal', activation='relu'))\n","model3.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n","\n","# 建立模型(4)\n","model4 = Sequential(name='MLP-3')\n","model4.add(Dense(units=256, input_dim=784, kernel_initializer='normal', activation='relu'))\n","model4.add(Dropout(0.5))\n","model4.add(Dense(units=256, kernel_initializer='normal', activation='relu'))\n","model4.add(Dense(units=10, kernel_initializer='normal', activation='softmax'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"adxH2plaoQio"},"source":["# model1.summary()\n","# model2.summary()\n","# model3.summary()\n","# model4.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxUnBSD7-kP9"},"source":["# 編譯模型\n","model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2S9rJwuUhXD4"},"source":["# 3. 訓練與分析"]},{"cell_type":"markdown","metadata":{"id":"RQhQp1eYutiI"},"source":["### 請依序進行 model1 到 model4 的訓練，並記錄結果"]},{"cell_type":"code","metadata":{"id":"iUERBRPU-6Ld"},"source":["# 每一訓練週期 epoch 會計算 accuracy 並記錄在 history\n","model = model4\n","history = model.fit(x=x_train_norm, y=y_train_onehot, validation_split=0.2, epochs=10, batch_size=200, verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A5l2Y5Oj_gpN"},"source":["### 建立函數 show_history 顯示訓練過程\n","\n"]},{"cell_type":"code","metadata":{"id":"Wow4oCGp_VmC"},"source":["# 使用自訂函數讀取 history 以圖表顯示訓練過程\n","def show_history(history, train, validation):\n","    fig = plt.gcf()\n","    fig.set_size_inches(8,3)\n","    plt.plot(history.history[train])  #訓練過程\n","    plt.plot(history.history[validation])  #驗證過程\n","    plt.title('Training History')  #標題\n","    plt.ylabel(train)   #縱軸是accuracy 與 loss 記錄\n","    plt.xlabel('Epoch')  #橫軸是訓練週期\n","    plt.legend(['train', 'validation'], loc='upper left')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rrgsf4-dhlbf"},"source":["### 觀察分析訓練結果"]},{"cell_type":"code","metadata":{"id":"sPCFbPU1_yhO"},"source":["# 比較訓練 loss 與驗證 loss\n","show_history(history, 'loss', 'val_loss')\n","show_history(history, 'accuracy', 'val_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KaqR9nRaAFPK"},"source":["### 測試及預測準確率\n"]},{"cell_type":"code","metadata":{"id":"P6xDBrmNACLz"},"source":["# 評估模型 x_test_norm\n","scores = model.evaluate(x_test_norm, y_test_onehot)\n","print('測試集準確率 = {:2.2f} %'.format(scores[1]*100.0))\n","\n","# 預測分類 x_test_norm\n","prediction_prob = model.predict(x_test_norm)\n","prediction = prediction_prob.argmax(axis = -1)\n","\n","num_right = sum(prediction==y_test)\n","num_wrong = sum(prediction!=y_test)\n","ratio = (10000-num_wrong) / 10000\n","print('正確數:', num_right, '\\t錯誤數:', num_wrong, '\\t正確率:', ratio)"],"execution_count":null,"outputs":[]}]}