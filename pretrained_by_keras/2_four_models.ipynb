{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BeQQoJcazPDo"},"source":["# Keras 提供的預訓練模型\n","1. MobileNetV2 (MobileNet)\n","2. ResNet50V2 (ResNet50)\n","3. InceptionV3\n","4. VGG19 (VGG16)\n"]},{"cell_type":"markdown","metadata":{"id":"XY-d-ugHz5sf"},"source":["## 起始準備 （Colab 連接雲端硬碟)"]},{"cell_type":"code","metadata":{"id":"UnaEHgaHz1gW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710917852891,"user_tz":-480,"elapsed":22772,"user":{"displayName":"Lo Chang-cheng (Dale_lo)","userId":"06634988243842920610"}},"outputId":"dbb47532-0bcc-404a-f2a4-1b4cd259d82d"},"source":["# 連接雲端硬碟，起始準備\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/class_AI/pretrained_by_keras/\n","!pwd\n","!ls"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/class_AI/pretrained_by_keras\n","/content/drive/MyDrive/class_AI/pretrained_by_keras\n","1_model_VGG16.ipynb  2_four_models.ipynb  koala.png  penguins.png\n"]}]},{"cell_type":"code","metadata":{"id":"cstRsfsj0NWS"},"source":["# 可依需要上傳檔案\n","from google.colab import files\n","uploaded = files.upload()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vfJY2CSU40R3","executionInfo":{"status":"ok","timestamp":1710919529183,"user_tz":-480,"elapsed":329,"user":{"displayName":"Lo Chang-cheng (Dale_lo)","userId":"06634988243842920610"}}},"source":["# 指定要預測的圖檔\n","filename = 'koala.png'"],"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# prompt: show image\"filename\"\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","img = mpimg.imread(filename)\n","imgplot = plt.imshow(img)\n","plt.show()\n"],"metadata":{"id":"OcrcYsygs1rR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bzv8j_U80O3P"},"source":["## 1. MobileNetV2 (MobileNet)"]},{"cell_type":"code","metadata":{"id":"K1gJNZ8Tyf0Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710919567677,"user_tz":-480,"elapsed":4546,"user":{"displayName":"Lo Chang-cheng (Dale_lo)","userId":"06634988243842920610"}},"outputId":"18c5274b-23bc-4325-b158-7541fc95fa3c"},"source":["from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n","from tensorflow.keras.preprocessing import image\n","\n","# 建立 MobileNetV2 模型\n","model = MobileNetV2(weights='imagenet', include_top=True)\n","# 載入測試圖片\n","img = image.load_img(filename, target_size=(224, 224))\n","x = image.img_to_array(img)    # 轉換成 Numpy陣列\n","print('x.shape: ', x.shape)\n","# Reshape (1, 224, 224, 3)\n","img = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n","# 資料預處理\n","img = preprocess_input(img)\n","print('img.shape: ', img.shape)\n","# 使用模型進行預測\n","Y_pred = model.predict(img)\n","# 解碼預測結果\n","label = decode_predictions(Y_pred, top=3)\n","result = label[0][0]  # 取得最可能的結果\n","print('%s (%.2f%%)' % (result[1], result[2]*100))\n","\n","for item in label[0]:\n","  print(item)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["x.shape:  (224, 224, 3)\n","img.shape:  (1, 224, 224, 3)\n","1/1 [==============================] - 1s 1s/step\n","koala (77.32%)\n","('n01882714', 'koala', 0.7732451)\n","('n01883070', 'wombat', 0.0051775393)\n","('n04074963', 'remote_control', 0.0037750094)\n"]}]},{"cell_type":"markdown","metadata":{"id":"d38-T-vV1cb6"},"source":["## 2. ResNet50V2 (ResNet50)"]},{"cell_type":"code","metadata":{"id":"BPyfncgD1kH4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710918921864,"user_tz":-480,"elapsed":5571,"user":{"displayName":"Lo Chang-cheng (Dale_lo)","userId":"06634988243842920610"}},"outputId":"5df22b5d-36b1-4fc6-9479-11323c156522"},"source":["from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input, decode_predictions\n","from tensorflow.keras.preprocessing import image\n","\n","# 建立 RasNet50V2 模型\n","model = ResNet50V2(weights='imagenet', include_top=True)\n","# 載入測試圖片\n","img = image.load_img(filename, target_size=(224, 224))\n","x = image.img_to_array(img)    # 轉換成 Numpy陣列\n","print('x.shape: ', x.shape)\n","# Reshape (1, 224, 224, 3)\n","img = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n","# 資料預處理\n","img = preprocess_input(img)\n","print('img.shape: ', img.shape)\n","# 使用模型進行預測\n","Y_pred = model.predict(img)\n","# 解碼預測結果\n","label = decode_predictions(Y_pred)\n","result = label[0][0]  # 取得最可能的結果\n","print('%s (%.2f%%)' % (result[1], result[2]*100))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["x.shape:  (224, 224, 3)\n","img.shape:  (1, 224, 224, 3)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78144a3589d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 2s 2s/step\n","king_penguin (99.99%)\n"]}]},{"cell_type":"markdown","metadata":{"id":"5Ve-kQl_2elD"},"source":["## 3. InceptionV3"]},{"cell_type":"code","metadata":{"id":"pGM24XT42h8F","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710919037199,"user_tz":-480,"elapsed":9007,"user":{"displayName":"Lo Chang-cheng (Dale_lo)","userId":"06634988243842920610"}},"outputId":"01b72caa-f032-4e36-d936-5a4bb3959deb"},"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.applications.inception_v3 import preprocess_input\n","from tensorflow.keras.applications.inception_v3 import decode_predictions\n","from tensorflow.keras.preprocessing import image\n","\n","# 建立 InceptionV3 模型\n","model = InceptionV3(weights='imagenet', include_top=True)\n","# 載入測試圖片\n","img = image.load_img(filename, target_size=(299, 299))\n","x = image.img_to_array(img)    # 轉換成 Numpy陣列\n","print('x.shape: ', x.shape)\n","# Reshape (1, 299, 299, 3)\n","img = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n","# 資料預處理\n","img = preprocess_input(img)\n","print('img.shape: ', img.shape)\n","# 使用模型進行預測\n","Y_pred = model.predict(img)\n","# 解碼預測結果\n","label = decode_predictions(Y_pred)\n","result = label[0][0]  # 取得最可能的結果\n","print('%s (%.2f%%)' % (result[1], result[2]*100))"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n","96112376/96112376 [==============================] - 1s 0us/step\n","x.shape:  (299, 299, 3)\n","img.shape:  (1, 299, 299, 3)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x781448d04550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 2s 2s/step\n","king_penguin (91.68%)\n"]}]},{"cell_type":"markdown","metadata":{"id":"EJm8WJbB2rC9"},"source":["## 4. VGG19 (VGG16)"]},{"cell_type":"code","metadata":{"id":"UnOAWRia2uI1"},"source":["from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input, decode_predictions\n","from tensorflow.keras.preprocessing import image\n","\n","# 建立 VGG19 模型\n","model = VGG19(weights='imagenet', include_top=True)\n","# 載入測試圖片\n","img = image.load_img(filename, target_size=(224, 224))\n","x = image.img_to_array(img)    # 轉換成 Numpy陣列\n","print('x.shape: ', x.shape)\n","# Reshape (1, 224, 224, 3)\n","img = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n","# 資料預處理\n","img = preprocess_input(img)\n","print('img.shape: ', img.shape)\n","# 使用模型進行預測\n","Y_pred = model.predict(img)\n","# 解碼預測結果\n","label = decode_predictions(Y_pred)\n","result = label[0][0]  # 取得最可能的結果\n","print('%s (%.2f%%)' % (result[1], result[2]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"St6KuDEPOJ3q"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N0tcvYTK5b4X"},"source":["## 練習"]},{"cell_type":"markdown","metadata":{"id":"1kbO4o8eNloo"},"source":["取得辨識分數最高的前三名"]},{"cell_type":"code","metadata":{"id":"aoOniUEjNjbp"},"source":["from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n","from tensorflow.keras.preprocessing import image\n","\n","# 建立 MobileNetV2 模型\n","model = MobileNetV2(weights='imagenet', include_top=True)\n","# 載入測試圖片\n","img = image.load_img(filename, target_size=(224, 224))\n","x = image.img_to_array(img)    # 轉換成 Numpy陣列\n","print('x.shape: ', x.shape)\n","# Reshape (1, 224, 224, 3)\n","img = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n","# 資料預處理\n","img = preprocess_input(img)\n","print('img.shape: ', img.shape)\n","# 使用模型進行預測\n","Y_pred = model.predict(img)\n","# 解碼預測結果\n","label = decode_predictions(Y_pred, top=3)\n","result = label[0][0]  # 取得最可能的結果\n","print('%s (%.2f%%)' % (result[1], result[2]*100))\n","\n","for item in label[0]:\n","  print(item)"],"execution_count":null,"outputs":[]}]}